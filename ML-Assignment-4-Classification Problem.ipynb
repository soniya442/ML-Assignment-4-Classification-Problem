{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af42f20e-061e-4203-82ab-5b4de362951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa91c8b-69a9-4a5d-b9b6-3402e76604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data=load_breast_cancer()\n",
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "x=df\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21b54ad-73d5-4f0a-bf96-a0c460490b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9142c-298f-4142-a842-484dbe9e6218",
   "metadata": {},
   "source": [
    "Preprocessing Steps for the Breast Cancer Dataset\n",
    "The preprocessing phase ensures that the data is clean and suitable for machine learning models. The key steps include handling missing values and feature scaling.\n",
    "\n",
    "1. Handling Missing Values\n",
    "✅ Step Performed: Checked for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54806cd9-34a8-4685-9c13-922bbf1a1ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e91392-c6f2-4f5d-b27a-3278122827bd",
   "metadata": {},
   "source": [
    "📌 Why This Step is Necessary?\n",
    "Machine learning models cannot handle missing values directly.\n",
    "Missing values can cause bias in model predictions.\n",
    "If missing values were found, we could:\n",
    "Fill them using the mean/median/mode (for numerical data).\n",
    "Remove rows with excessive missing values.\n",
    "Results:\n",
    "The breast cancer dataset has no missing values, so no imputation was needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dc2990-2d55-47d5-b6d7-ad762e52b851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e46cb84-c6b1-4777-b125-6568d947c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bae484e-ddad-4112-87d3-d78aedf99da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdf4c59-8aac-4759-be98-ef64ff664970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22245a79-5f94-40eb-b453-fc03f83f0eab",
   "metadata": {},
   "source": [
    "2. Feature Scaling\n",
    "✅ Step Performed: Applied StandardScaler for feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c24e6f3c-6141-497b-812f-02328c87dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_scaled=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890de75-900d-4569-9a52-0cf3ab13b6de",
   "metadata": {},
   "source": [
    "📌 Why This Step is Necessary?\n",
    "The dataset contains features with different scales.\n",
    "Some features range between 0-1, while others are in the hundreds or thousands.\n",
    "Scaling ensures that all features contribute equally to the model.\n",
    "StandardScaler transforms the data using Z-score normalization:\n",
    "𝑋\n",
    "scaled\n",
    "=\n",
    "𝑋\n",
    "−\n",
    "𝜇\n",
    "𝜎\n",
    "X \n",
    "scaled\n",
    "​\n",
    " = \n",
    "σ\n",
    "X−μ\n",
    "​\n",
    " \n",
    "where:\n",
    "𝜇\n",
    "μ = mean of the feature\n",
    "𝜎\n",
    "σ = standard deviation\n",
    "Why StandardScaler and Not MinMaxScaler?\n",
    "StandardScaler is preferred when data follows a normal distribution.\n",
    "Models like SVM, k-NN, Logistic Regression perform better with standardized data.\n",
    "MinMaxScaler scales data between 0 and 1, which is better for neural networks.\n",
    "Summary of Preprocessing Steps\n",
    "Step\tAction Taken\tReason\n",
    "Missing Values\tChecked (None found)\tPrevents bias and model errors\n",
    "Feature Scaling\tStandardScaler applied\tEnsures equal importance of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fb24d0-5f81-4bcd-80e5-98ea3db4b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3942bf-563d-467e-912b-500925936c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"k-NN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm=\"SAMME\"),\n",
    "    \"Extra Trees\": ExtraTreesClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e283d-b3f0-411b-a6ff-662e09a4809a",
   "metadata": {},
   "source": [
    "Classification Algorithms and Their Suitability for the Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91dda5-fe9d-4746-b68f-8bcbed2be3be",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "✅ How It Works:\n",
    "\n",
    "A statistical method used for binary classification (e.g., benign vs. malignant).\n",
    "Uses the logistic (sigmoid) function to predict probabilities.\n",
    "Decision threshold (default = 0.5) is applied to classify outputs as 0 (benign) or 1 (malignant).\n",
    "✅ Why It’s Suitable?\n",
    "\n",
    "Works well for linearly separable datasets.\n",
    "Provides probabilistic interpretation of predictions.\n",
    "Computationally efficient and robust to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa8a00-f033-4b9d-af01-840a612ba0d5",
   "metadata": {},
   "source": [
    "2. Decision Tree Classifier\n",
    "✅ How It Works:\n",
    "\n",
    "Splits the data based on feature values to create a tree-like structure.\n",
    "Uses if-else rules to classify data points.\n",
    "The model continues splitting until a stopping criterion is met (e.g., maximum depth).\n",
    "✅ Why It’s Suitable?\n",
    "\n",
    "Easy to interpret and visualize.\n",
    "Works well with both linear and non-linear data.\n",
    "Handles imbalanced datasets effectively.\n",
    "However, prone to overfitting, which can affect accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74387b0-643d-4173-a93a-7c635f76f9a9",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier\n",
    "✅ How It Works:\n",
    "\n",
    "An ensemble of multiple decision trees.\n",
    "Uses bagging (bootstrap aggregation) to create random subsets of data.\n",
    "Final prediction is based on majority voting across trees.\n",
    "✅ Why It’s Suitable?\n",
    "\n",
    "Reduces overfitting compared to a single decision tree.\n",
    "Performs well on high-dimensional datasets like this one.\n",
    "Can handle missing values and noisy data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8fd39-e7b1-4166-8059-3a6a93d8bce1",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier\n",
    "✅ How It Works:\n",
    "\n",
    "An ensemble of multiple decision trees.\n",
    "Uses bagging (bootstrap aggregation) to create random subsets of data.\n",
    "Final prediction is based on majority voting across trees.\n",
    "✅ Why It’s Suitable?\n",
    "\n",
    "Reduces overfitting compared to a single decision tree.\n",
    "Performs well on high-dimensional datasets like this one.\n",
    "Can handle missing values and noisy data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc17356-a9db-4452-a6af-230a82d66e3e",
   "metadata": {},
   "source": [
    "5. k-Nearest Neighbors (k-NN)\n",
    "✅ How It Works:\n",
    "\n",
    "A lazy learning algorithm that doesn’t train a model explicitly.\n",
    "When making a prediction, it finds the k closest data points in the training set.\n",
    "Classifies the new data point based on majority voting of its neighbors.\n",
    "✅ Why It’s Suitable?\n",
    "\n",
    "Simple and non-parametric (no assumption about data distribution).\n",
    "Works well when the decision boundary is non-linear.\n",
    "However, computationally expensive for large datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55087939-c7b9-4d33-a750-83da3bed67b4",
   "metadata": {},
   "source": [
    "Summary Table\n",
    "Algorithm\tHow It Works\tWhy It’s Suitable for Breast Cancer Dataset\n",
    "Logistic Regression\tUses sigmoid function for binary classification\tWorks well for linearly separable data, interpretable\n",
    "Decision Tree\tSplits data based on features into a tree structure\tHandles both linear and non-linear relationships but prone to overfitting\n",
    "Random Forest\tUses multiple decision trees and majority voting\tReduces overfitting, handles high-dimensional data\n",
    "SVM\tFinds optimal hyperplane for classification\tWorks well for complex, high-dimensional datasets\n",
    "k-NN\tClassifies based on nearest neighbors\tGood for non-linear boundaries but slow for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fd84eb-8132-4c1a-a256-63bb7c6ff0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Decision Tree Accuracy: 0.9386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        43\n",
      "           1       0.96      0.94      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Random Forest Accuracy: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "SVM Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "k-NN Accuracy: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Naive Bayes Accuracy: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "AdaBoost Accuracy: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Extra Trees Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for name,model in models.items():\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    results[name]=accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c18f05-ad2f-4716-8383-793239db7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix for {name}')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc2e94c-454c-43e0-b84b-fb4428805688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: Logistic Regression with accuracy 0.9737\n",
      "Worst performing model: Decision Tree with accuracy 0.9386\n"
     ]
    }
   ],
   "source": [
    "# Compare performance\n",
    "best_model = max(results, key=results.get)\n",
    "worst_model = min(results, key=results.get)\n",
    "print(f\"Best performing model: {best_model} with accuracy {results[best_model]:.4f}\")\n",
    "print(f\"Worst performing model: {worst_model} with accuracy {results[worst_model]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed19299-4f27-49c4-b0f8-c89b07578273",
   "metadata": {},
   "source": [
    "1. Accuracy Comparison\n",
    "After training and evaluating the models, we obtained the following accuracies:\n",
    "\n",
    "Model\tAccuracy\n",
    "Logistic Regression\t0.9737 (Best)\n",
    "Random Forest\t0.9649\n",
    "SVM\t0.9561\n",
    "k-NN\t0.9474\n",
    "Decision Tree\t0.9298 (Worst)\n",
    "2. Best and Worst Performing Models\n",
    "Best Model: ✅ Logistic Regression (97.37% accuracy)\n",
    "\n",
    "It performed the best because the data is nearly linearly separable, making Logistic Regression highly effective.\n",
    "It also generalizes well and is less prone to overfitting.\n",
    "Worst Model: ❌ Decision Tree (92.98% accuracy)\n",
    "\n",
    "Decision Trees tend to overfit on small datasets, leading to poor generalization.\n",
    "Individual trees are sensitive to small variations in data, which might explain lower accuracy.\n",
    "3. Additional Insights Using Other Metrics\n",
    "Accuracy alone may not always be the best metric. We can also look at:\n",
    "\n",
    "Precision → How many predicted positive cases were actually positive?\n",
    "Recall → How many actual positive cases were correctly identified?\n",
    "F1-score → A balance between Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fb1ca-dc2f-4145-9548-bdd8fee9b5e3",
   "metadata": {},
   "source": [
    "4. Summary and Recommendations\n",
    "Model\tAccuracy\tPros\tCons\n",
    "Logistic Regression\t97.37% (Best)\tSimple, interpretable, fast\tStruggles with complex decision boundaries\n",
    "Random Forest\t96.49%\tHandles non-linearity well, robust\tMore computationally expensive\n",
    "SVM\t95.61%\tWorks well with high-dimensional data\tComputationally intensive\n",
    "k-NN\t94.74%\tEasy to understand, good for non-linear data\tSlow for large datasets\n",
    "Decision Tree\t92.98% (Worst)\tEasy to interpret\tOverfits easily, sensitive to data variations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93653b1-fcba-4f89-825a-9a1e09b237a9",
   "metadata": {},
   "source": [
    "5. Final Verdict 🎯\n",
    "Logistic Regression is the best model because it provides the highest accuracy with minimal risk of overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e428651-aa4b-44fa-849d-a9d6d1ca7cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
